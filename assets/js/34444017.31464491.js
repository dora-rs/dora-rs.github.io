"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[6562],{60514:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var o=n(74848),s=n(28453);const r={sidebar_position:4},a="LLMs",i={id:"guides/getting-started/llm",title:"LLMs",description:"Adding LLMs to our dataflow",source:"@site/docs/guides/getting-started/llm.md",sourceDirName:"guides/getting-started",slug:"/guides/getting-started/llm",permalink:"/docs/guides/getting-started/llm",draft:!1,unlisted:!1,editUrl:"https://github.com/dora-rs/dora-rs.github.io/edit/main/docs/guides/getting-started/llm.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"guides",previous:{title:"Yolov8",permalink:"/docs/guides/getting-started/yolov8"},next:{title:"Arrow",permalink:"/docs/guides/Development/Arrow"}},d={},c=[{value:"Adding LLMs to our dataflow",id:"adding-llms-to-our-dataflow",level:2},{value:"<code>record</code> speech to text",id:"record-speech-to-text",level:2},{value:"<code>change</code> source node",id:"change-source-node",level:2},{value:"<code>ask</code> a question to the assistant",id:"ask-a-question-to-the-assistant",level:2},{value:"<code>send</code> a message to the dataflow",id:"send-a-message-to-the-dataflow",level:2},{value:"Getting started",id:"getting-started",level:2}];function l(e){const t={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"llms",children:"LLMs"}),"\n",(0,o.jsx)(t.h2,{id:"adding-llms-to-our-dataflow",children:"Adding LLMs to our dataflow"}),"\n",(0,o.jsx)(t.p,{children:"Let's add additional operators:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"wget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/keyboard_op.py\nwget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/microphone_op.py\nwget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/whisper_op.py\nwget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/sentence_transformers_op.py\nwget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/llm_op.py\nwget https://raw.githubusercontent.com/dora-rs/dora/v0.3.6/examples/python-operator-dataflow/file_saver_op.py\n"})}),"\n",(0,o.jsx)(t.p,{children:"and the dataflow configuration:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",metastring:"{24-87}",children:"nodes:\n  - id: webcam\n    operator:\n      python: webcam.py\n      inputs:\n        tick: dora/timer/millis/50\n      outputs:\n        - image\n\n  - id: object_detection\n    operator:\n      python: object_detection.py\n      inputs:\n        image: webcam/image\n      outputs:\n        - bbox\n\n  - id: plot\n    operator:\n      python: plot.py\n      inputs:\n        image: webcam/image\n        bbox: object_detection/bbox\n        line: llm/line\n        keyboard_buffer: keyboard/buffer\n        user_message: keyboard/submitted\n        assistant_message: llm/assistant_message\n\n  ## Speech to text\n  - id: keyboard\n    custom:\n      source: keyboard_op.py\n      outputs:\n        - buffer\n        - submitted\n        - record\n        - ask\n        - send\n        - change\n      inputs:\n        recording: whisper/text\n\n  - id: microphone\n    operator:\n      python: microphone_op.py\n      inputs:\n        record: keyboard/record\n      outputs:\n        - audio\n\n  - id: whisper\n    operator:\n      python: whisper_op.py\n      inputs:\n        audio: microphone/audio\n      outputs:\n        - text\n\n  ## Code Modifier\n  - id: vectordb\n    operator:\n      python: sentence_transformers_op.py\n      inputs:\n        query: keyboard/change\n        saved_file: file_saver/saved_file\n      outputs:\n        - raw_file\n\n  - id: llm\n    operator:\n      python: llm_op.py\n      inputs:\n        code_modifier: vectordb/raw_file\n        assistant: keyboard/ask\n        message_sender: keyboard/send\n      outputs:\n        - modified_file\n        - line\n        - assistant_message\n\n  - id: file_saver\n    operator:\n      python: file_saver_op.py\n      inputs:\n        file: llm/modified_file\n      outputs:\n        - saved_file\n"})}),"\n",(0,o.jsx)(t.p,{children:"Try it out with:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"dora up\ndora start dataflow.yml --attach\n"})}),"\n",(0,o.jsxs)(t.h2,{id:"record-speech-to-text",children:[(0,o.jsx)(t.code,{children:"record"})," speech to text"]}),"\n",(0,o.jsx)(t.p,{children:"The keyboard will record every key input of the keyboard."}),"\n",(0,o.jsxs)(t.p,{children:["If the keyboard receive submit the keyword ",(0,o.jsx)(t.code,{children:"record"}),", the microphone is going to be triggered and the audio is going to be transcripted using OpenAI whisper."]}),"\n",(0,o.jsxs)(t.h2,{id:"change-source-node",children:[(0,o.jsx)(t.code,{children:"change"})," source node"]}),"\n",(0,o.jsxs)(t.p,{children:["The code modification flow works by first submitting an instruction with the keyword ",(0,o.jsx)(t.code,{children:"change"}),". The instruction is then going to be passed on the vectorDB to retrieve the closest node source code for it to be changed."]}),"\n",(0,o.jsx)(t.p,{children:"The source code and the instruction is then fed to an LLM to be modified, which is then saved into the source code."}),"\n",(0,o.jsx)(t.p,{children:"This later triggers a hot-reloading sequence for the node to be reloaded."}),"\n",(0,o.jsx)(t.p,{children:"The end result should correspond to the instruction."}),"\n",(0,o.jsx)("p",{align:"center",children:(0,o.jsx)("img",{src:"/img/RAG.svg",width:"800"})}),"\n",(0,o.jsxs)(t.h2,{id:"ask-a-question-to-the-assistant",children:[(0,o.jsx)(t.code,{children:"ask"})," a question to the assistant"]}),"\n",(0,o.jsxs)(t.p,{children:["You can ask a question to the assistant by submitting the keyword ",(0,o.jsx)(t.code,{children:"ask"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"The question is then going to be passed to the LLM which will reply in the window."}),"\n",(0,o.jsxs)(t.h2,{id:"send-a-message-to-the-dataflow",children:[(0,o.jsx)(t.code,{children:"send"})," a message to the dataflow"]}),"\n",(0,o.jsxs)(t.p,{children:["You can also send a message directly to the dataflow by using the keyword ",(0,o.jsx)(t.code,{children:"send"})," and then specifying the data that you want set."]}),"\n",(0,o.jsx)(t.p,{children:"Note that the data and topic should be specified both in the dataflow and in the LLM node to send data`"}),"\n",(0,o.jsx)(t.h2,{id:"getting-started",children:"Getting started"}),"\n",(0,o.jsx)(t.p,{children:"You can try the following instruction:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"ask how are you\nchange bounding box plot to red\nchange confidence value to percentage\nchange object detection to only detect person\nsend 200 200 200 400 to topic line\nrecord # Then speak\n"})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>i});var o=n(96540);const s={},r=o.createContext(s);function a(e){const t=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);