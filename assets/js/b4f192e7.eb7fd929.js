"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[2099],{62870:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var t=o(74848),r=o(28453);const s={},a="Strong Sort operator",i={id:"nodes_operators/strong_sort_op",title:"Strong Sort operator",description:"Strong sort uses deep learning to uniquely identify bounding boxes in order to track them trough an image stream.",source:"@site/docs/nodes_operators/strong_sort_op.md",sourceDirName:"nodes_operators",slug:"/nodes_operators/strong_sort_op",permalink:"/docs/nodes_operators/strong_sort_op",draft:!1,unlisted:!1,editUrl:"https://github.com/dora-rs/dora-rs.github.io/edit/main/docs/nodes_operators/strong_sort_op.md",tags:[],version:"current",frontMatter:{},sidebar:"nodes_operators",previous:{title:"Plot operator",permalink:"/docs/nodes_operators/plot"},next:{title:"Webcam operator",permalink:"/docs/nodes_operators/webcam_op"}},d={},l=[{value:"Inputs",id:"inputs",level:2},{value:"Outputs",id:"outputs",level:2},{value:"Example plot (Tracking correspond to the blue # id )",id:"example-plot-tracking-correspond-to-the-blue--id-",level:2},{value:"Graph Description",id:"graph-description",level:2},{value:"Graph Visualisation",id:"graph-visualisation",level:2},{value:"Methods",id:"methods",level:2},{value:"<code>__init__()</code>",id:"__init__",level:3},{value:"<code>.on_event(...)</code>",id:"on_event",level:3},{value:"<code>.on_input(...)</code>",id:"on_input",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"strong-sort-operator",children:"Strong Sort operator"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Strong sort"})," uses deep learning to uniquely identify bounding boxes in order to track them trough an image stream."]}),"\n",(0,t.jsx)(n.h2,{id:"inputs",children:"Inputs"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"image: HEIGHTxWIDTHxBGR array."}),"\n",(0,t.jsx)(n.li,{children:"bbox: N_BBOX, X_MIN, X_MAX, Y_MIN, Y_MAX, CONDIDENCE, CLASS, array"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"outputs",children:"Outputs"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"obstacles_id: x1, x2, y1, y2 track_id, class_id, conf"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"example-plot-tracking-correspond-to-the-blue--id-",children:"Example plot (Tracking correspond to the blue # id )"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"https://i.imgur.com/ozO1y7l.gif",alt:"img"})}),"\n",(0,t.jsx)(n.h2,{id:"graph-description",children:"Graph Description"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"  - id: yolov5\n    operator: \n      outputs:\n        - obstacles_id\n      inputs:\n        image: webcam/image\n        bbox: yolov5/bbox\n      python: ../../operators/strong_sort_op.py\n"})}),"\n",(0,t.jsx)(n.h2,{id:"graph-visualisation",children:"Graph Visualisation"}),"\n",(0,t.jsx)(n.mermaid,{value:"        flowchart TB\n  oasis_agent -- image --\x3e strong_sort/op\n  yolov5/op -- bbox as obstacles_bbox --\x3e strong_sort/op"}),"\n",(0,t.jsx)(n.h2,{id:"methods",children:"Methods"}),"\n",(0,t.jsx)(n.h3,{id:"__init__",children:(0,t.jsx)(n.code,{children:"__init__()"})}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Source Code"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'    def __init__(self):\n        model = StrongSORT(\n            "osnet_x0_25_msmt17.pt",\n            torch.device("cuda"),\n            False,\n        )\n        model.model.warmup()\n        self.model = model\n        self.frame = []\n\n\n'})})]}),"\n",(0,t.jsx)(n.h3,{id:"on_event",children:(0,t.jsx)(n.code,{children:".on_event(...)"})}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Source Code"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'\n    def on_event(\n        self,\n        dora_event: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n\n'})})]}),"\n",(0,t.jsx)(n.h3,{id:"on_input",children:(0,t.jsx)(n.code,{children:".on_input(...)"})}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Source Code"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'\n    def on_input(\n        self,\n        dora_input: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_input["id"] == "image":\n            frame = np.array(\n                dora_input["value"],\n                np.uint8,\n            ).reshape((IMAGE_HEIGHT, IMAGE_WIDTH, 4))\n\n            self.frame = frame[:, :, :3]\n\n        elif dora_input["id"] == "obstacles_bbox" and len(self.frame) != 0:\n            obstacles = np.array(dora_input["value"]).reshape((-1, 6))\n            if obstacles.shape[0] == 0:\n                # self.model.increment_ages()\n                send_output(\n                    "obstacles_id",\n                    pa.array(np.array([]).ravel()),\n                    dora_input["metadata"],\n                )\n                return DoraStatus.CONTINUE\n\n            # Post Processing yolov5\n            xywhs = xxyy2xywh(obstacles[:, 0:4])\n            confs = obstacles[:, 4]\n            clss = obstacles[:, 5]\n            with torch.no_grad():\n                outputs = np.array(\n                    self.model.update(xywhs, confs, clss, self.frame)\n                ).astype("int32")\n                if len(outputs) != 0:\n                    outputs = outputs[\n                        :, [0, 2, 1, 3, 4, 5, 6]\n                    ]  # xyxy -> x1, x2, y1, y2 track_id, class_id, conf\n\n                    send_output(\n                        "obstacles_id",\n                        pa.array(outputs.ravel()),\n                        dora_input["metadata"],\n                    )\n\n        return DoraStatus.CONTINUE\n\n\n'})})]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>a,x:()=>i});var t=o(96540);const r={},s=t.createContext(r);function a(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);