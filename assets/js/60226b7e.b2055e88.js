"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[9829],{6310:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var o=t(4848),a=t(8453);const s={sidebar_position:3},r="Yolov8",i={id:"guides/getting-started/yolov8",title:"Yolov8",description:"Making the video stream intelligent",source:"@site/docs/guides/getting-started/yolov8.md",sourceDirName:"guides/getting-started",slug:"/guides/getting-started/yolov8",permalink:"/docs/guides/getting-started/yolov8",draft:!1,unlisted:!1,editUrl:"https://github.com/dora-rs/dora-rs.github.io/edit/main/docs/guides/getting-started/yolov8.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"guides",previous:{title:"Webcam Plot",permalink:"/docs/guides/getting-started/webcam_plot"},next:{title:"LLMs",permalink:"/docs/guides/getting-started/llm"}},d={},c=[{value:"Making the video stream intelligent",id:"making-the-video-stream-intelligent",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"yolov8",children:"Yolov8"}),"\n",(0,o.jsx)(n.h2,{id:"making-the-video-stream-intelligent",children:"Making the video stream intelligent"}),"\n",(0,o.jsxs)(n.p,{children:["Let's add a ",(0,o.jsx)(n.code,{children:"yolov8"})," object detection operator, that you can ",(0,o.jsx)(n.a,{href:"https://raw.githubusercontent.com/dora-rs/dora/v0.3.5/examples/python-operator-dataflow/object_detection.py",children:"find as an example"}),". This will help us detect object as bounding boxes within the webcam stream."]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Install required dependencies"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"conda create -n example_env python=3.11\nconda activate test_env\npip install -r https://raw.githubusercontent.com/dora-rs/dora/v0.3.5/examples/python-operator-dataflow/requirements.txt\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Create a new ",(0,o.jsx)(n.code,{children:"object_detection.py"})," python file with the following content"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"wget https://raw.githubusercontent.com/dora-rs/dora/v0.3.5/examples/python-operator-dataflow/object_detection.py\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"object_detection.py"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport pyarrow as pa\n\nfrom dora import DoraStatus\nfrom ultralytics import YOLO\n\npa.array([])\n\nCAMERA_WIDTH = 640\nCAMERA_HEIGHT = 480\n\nclass Operator:\n    def __init__(self):\n        self.model = YOLO("yolov8n.pt")\n\n    def on_event(\n        self,\n        dora_event,\n        send_output,\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n    def on_input(\n        self,\n        dora_input,\n        send_output,\n    ) -> DoraStatus:\n\n        frame = dora_input["value"].to_numpy().reshape((CAMERA_HEIGHT, CAMERA_WIDTH, 3))\n        frame = frame[:, :, ::-1]  # OpenCV image (BGR to RGB)\n        results = self.model(frame)  # includes NMS\n        # Process results\n        boxes = np.array(results[0].boxes.xyxy.cpu())\n        conf = np.array(results[0].boxes.conf.cpu())\n        label = np.array(results[0].boxes.cls.cpu())\n        # concatenate them together\n        arrays = np.concatenate((boxes, conf[:, None], label[:, None]), axis=1)\n\n        send_output("bbox", pa.array(arrays.ravel()), dora_input["metadata"])\n        return DoraStatus.CONTINUE\n'})}),"\n",(0,o.jsx)(n.p,{children:"Operators are composed of:"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"on_event"})," methods is called when an event is received.\nThere is currently 4 event types:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"STOP"}),": meaning that the operator was signalled to stop."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"INPUT"}),": meannig that an input was received.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["You can use ",(0,o.jsx)(n.code,{children:"dora_event['id']"}),", to get the id."]}),"\n",(0,o.jsxs)(n.li,{children:["You can use ",(0,o.jsx)(n.code,{children:"dora_event['data']"}),", to get the data as bytes."]}),"\n",(0,o.jsxs)(n.li,{children:["You can use ",(0,o.jsx)(n.code,{children:"dora_event['value']"}),", to get the data as arrow array."]}),"\n",(0,o.jsxs)(n.li,{children:["You can use ",(0,o.jsx)(n.code,{children:"dora_event['metadata']"}),", to get the metadata."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"INPUT_CLOSED"}),": meannig that an input source was closed. This could be useful if the input is critical for the well behaviour of the operator."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ERROR"}),": meaning that error message was received."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"UNKNOWN"}),": meaning that an unknown message was received."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Add an operator within the dataflow"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"wget https://raw.githubusercontent.com/dora-rs/dora/v0.3.5/examples/python-operator-dataflow/dataflow.yaml\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"dataflow.yaml"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",metastring:"{10-16,23}",children:"nodes:\n  - id: webcam\n    operator:\n      python: webcam.py\n      inputs:\n        tick: dora/timer/millis/100\n      outputs:\n        - image\n\n  - id: object_detection\n    operator:\n      python: object_detection.py\n      inputs:\n        image: webcam/image\n      outputs:\n        - bbox\n\n  - id: plot\n    operator:\n      python: plot.py\n      inputs:\n        image: webcam/image\n        bbox: object_detection/bbox\n"})}),"\n",(0,o.jsxs)(n.p,{children:["In this case, we have connected the ",(0,o.jsx)(n.code,{children:"webcam/image"})," output to the ",(0,o.jsx)(n.code,{children:"image"})," input of yolov8. ",(0,o.jsx)(n.code,{children:"object_detection/bbox"})," is then connected to the ",(0,o.jsx)(n.code,{children:"plot/obstacles_bbox"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"Inputs are prefixed by the node name to be able to separate name conflicts."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"run"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"dora up\ndora start dataflow.yml --attach\n"})}),"\n",(0,o.jsx)("p",{align:"center",children:(0,o.jsx)("img",{src:"/img/webcam_yolov5.png",width:"800"})}),"\n",(0,o.jsx)(n.p,{children:"The plot will show object detected in the image as bounding box with a label and a confidence score."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var o=t(6540);const a={},s=o.createContext(a);function r(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);