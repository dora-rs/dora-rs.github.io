"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[1105],{28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(96540);const o={},a=i.createContext(o);function r(e){const t=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(a.Provider,{value:t},e.children)}},67868:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var i=n(84001),o=n(74848),a=n(28453);const r={authors:"haixuan",title:"Reachy2 Pick and Place",description:"Using reachy2 with QwenVL2.5 to pick object and put it in a brown bag."},s=void 0,c={authorsImageUrls:[void 0]},l=[{value:"Using qwenVL 2.5 multi bounding box capabilities to pick and place mulitple item with very low latency.",id:"using-qwenvl-25-multi-bounding-box-capabilities-to-pick-and-place-mulitple-item-with-very-low-latency",level:5},{value:"Rerun",id:"rerun",level:2},{value:"Code",id:"code",level:2},{value:"Demo",id:"demo",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h5:"h5",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h5,{id:"using-qwenvl-25-multi-bounding-box-capabilities-to-pick-and-place-mulitple-item-with-very-low-latency",children:"Using qwenVL 2.5 multi bounding box capabilities to pick and place mulitple item with very low latency."}),"\n",(0,o.jsx)(t.h2,{id:"rerun",children:"Rerun"}),"\n",(0,o.jsx)("iframe",{src:"https://app.rerun.io/version/0.21.0/index.html?url=https://huggingface.co/datasets/haixuantao/rerun_dataset/resolve/main/final_chocolate_in_hand.rrd",width:"100%",height:"700px"}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsx)(t.p,{children:"In case Rerun does not work on your phone. You'll find the video below:"}),"\n",(0,o.jsx)("video",{controls:!0,src:"https://huggingface.co/datasets/haixuantao/rerun_dataset/resolve/main/2025-02-25%2020-19-46.mp4#t=10",width:"100%"}),"\n",(0,o.jsx)(t.p,{children:"In the above iframe, the important information are:"}),"\n"]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"/text_whisper"}),": correspond to ",(0,o.jsx)(t.strong,{children:"whisper"})," audio transcription."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"/text_response"}),": correspond to the bounding box given as plain text from ",(0,o.jsx)(t.strong,{children:"QwenVL 2.5"})]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"camera_torso"}),": correspond to ",(0,o.jsx)(t.strong,{children:"Orbecc Gemini 336 Depth Camera"})," rgb image."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"camera_torso"})," bounding box: correspond to the QwenVL bounding box projected on the image that is going to be used to grasp object. The prediction is done at regular interval and does not disappear. Sorry if it can be a bit confusing."]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"code",children:"Code"}),"\n",(0,o.jsxs)(t.p,{children:["The branch: ",(0,o.jsx)(t.a,{href:"https://github.com/dora-rs/dora/pull/793",children:"https://github.com/dora-rs/dora/pull/793"})]}),"\n",(0,o.jsx)(t.h2,{id:"demo",children:"Demo"}),"\n",(0,o.jsx)("video",{controls:!0,src:"https://huggingface.co/datasets/haixuantao/rerun_dataset/resolve/main/temp_video_1740509513726.mp4",width:"100%"})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},84001:e=>{e.exports=JSON.parse('{"permalink":"/zh-CN/blog/reachy-pick-place","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/reachy-pick-place.md","source":"@site/blog/reachy-pick-place.md","title":"Reachy2 Pick and Place","description":"Using reachy2 with QwenVL2.5 to pick object and put it in a brown bag.","date":"2025-11-20T08:24:59.000Z","tags":[],"readingTime":0.9,"hasTruncateMarker":false,"authors":[{"name":"Haixuan Xavier Tao","title":"Maintainer of dora-rs","url":"https://github.com/haixuantao","imageURL":"https://github.com/haixuantao.png","key":"haixuan","page":null}],"frontMatter":{"authors":"haixuan","title":"Reachy2 Pick and Place","description":"Using reachy2 with QwenVL2.5 to pick object and put it in a brown bag."},"unlisted":false,"nextItem":{"title":"Reachy2 Speech-to-Grasp","permalink":"/zh-CN/blog/reachy-qwenvl-sam2"}}')}}]);