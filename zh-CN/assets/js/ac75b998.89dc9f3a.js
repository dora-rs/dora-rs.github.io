"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[4139],{14594:(n,o,e)=>{e.r(o),e.d(o,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>r});var t=e(74848),l=e(28453);const i={},a="Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u7b97\u5b50",s={id:"nodes_operators/obstacle_location_op",title:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u7b97\u5b50",description:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u7b97\u5b50\u5339\u914d\u5e26\u6709\u6df1\u5ea6\u6846\u67b6\u7684\u8fb9\u754c\u6846\uff0c\u7528\u4e8e\u67e5\u627e\u969c\u788d\u7269\u7684\u8fd1\u4f3c\u4f4d\u7f6e\u3002",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/nodes_operators/obstacle_location_op.md",sourceDirName:"nodes_operators",slug:"/nodes_operators/obstacle_location_op",permalink:"/zh-CN/docs/nodes_operators/obstacle_location_op",draft:!1,unlisted:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",frontMatter:{}},c={},r=[{value:"\u8f93\u5165",id:"\u8f93\u5165",level:2},{value:"\u8f93\u51fa",id:"\u8f93\u51fa",level:2},{value:"\u793a\u4f8b\u7ed8\u5236 \uff08\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9\uff09",id:"\u793a\u4f8b\u7ed8\u5236-\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9",level:2},{value:"\u56fe\u63cf\u8ff0",id:"\u56fe\u63cf\u8ff0",level:2},{value:"\u56fe\u53ef\u89c6\u5316",id:"\u56fe\u53ef\u89c6\u5316",level:2},{value:"\u65b9\u6cd5",id:"\u65b9\u6cd5",level:2},{value:"<code>__init__()</code>",id:"__init__",level:3},{value:"<code>.on_event(...)</code>",id:"on_event",level:3},{value:"<code>.on_input(...)</code>",id:"on_input",level:3}];function _(n){const o={code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...n.components},{Details:e}=o;return e||function(n,o){throw new Error("Expected "+(o?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.h1,{id:"obstacle-location-\u969c\u788d\u7269\u4f4d\u7f6e-\u7b97\u5b50",children:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u7b97\u5b50"}),"\n",(0,t.jsx)(o.p,{children:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u7b97\u5b50\u5339\u914d\u5e26\u6709\u6df1\u5ea6\u6846\u67b6\u7684\u8fb9\u754c\u6846\uff0c\u7528\u4e8e\u67e5\u627e\u969c\u788d\u7269\u7684\u8fd1\u4f3c\u4f4d\u7f6e\u3002"}),"\n",(0,t.jsx)(o.p,{children:"\u5176\u4e2d\u6709\u4e24\u4e2a\u903b\u8f91\uff1a"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsx)(o.li,{children:"\u4e00\u4e2a\u662f\u7528\u4e8e\u8f66\u9053\u68c0\u6d4b\u7684\u63a5\u5730\u70b9\u3002"}),"\n",(0,t.jsx)(o.li,{children:"\u4e00\u4e2a\u662f\u8fb9\u754c\u6846\u969c\u788d\u7269\u5b9a\u4f4d\u3002"}),"\n"]}),"\n",(0,t.jsx)(o.p,{children:"\u8fd9\u4e24\u79cd\u903b\u8f91\u90fd\u662f\u57fa\u4e8e\u5bf9\u6fc0\u5149\u96f7\u8fbe 3D \u70b9\u5728 2D \u7a7a\u95f4\u4e2d\u7684\u6295\u5f71\u8fdb\u884c\u8ba1\u7b97\uff0c\u7136\u540e\u91cd\u7528\u7d22\u5f15\u6765\u83b7\u53d6 3D \u4f4d\u7f6e\u3002"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsx)(o.li,{children:"\u5728\u63a5\u5730\u70b9\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd1\u4f3c\u503c\u57fa\u4e8e\u4e00\u4e2a K\u90bb\u8fd1\u56de\u5f52\uff0c\u56e0\u4e3a\u6211\u4eec\u53ef\u80fd\u6ca1\u6709\u8db3\u591f\u7684\u5730\u9762\u6570\u636e\u3002"}),"\n",(0,t.jsx)(o.li,{children:"\u5728\u8fb9\u754c\u6846\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4f7f\u7528\u8fb9\u754c\u6846\u5185\u7684\u7b2c\u4e00\u4e2a\u5206\u4f4d\u6570\u6700\u8fd1\u70b9\u6765\u4f30\u8ba1\u8ddd\u79bb\u3002 \u6211\u4eec\u4f7f\u7528\u7b2c\u4e00\u4e2a\u5206\u4f4d\u6570\u6700\u8fd1\u70b9\u6765\u6d88\u9664\u566a\u58f0\u3002"}),"\n"]}),"\n",(0,t.jsxs)(o.p,{children:["\u5c06\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u6295\u5f71\u5230 2D \u4e2d\u7684\u673a\u68b0\u6027\u4e5f\u7528\u4e8e ",(0,t.jsx)(o.code,{children:"plot.py"})," \u7b97\u5b50\u4e2d\u3002 \u60a8\u53ef\u4ee5\u4f7f\u7528\u5176\u4e2d\u8f93\u5165 ",(0,t.jsx)(o.code,{children:"lidar_pc"})," \u5e2e\u52a9\u60a8\u8fdb\u884c\u8c03\u8bd5\u3002"]}),"\n",(0,t.jsx)(o.h2,{id:"\u8f93\u5165",children:"\u8f93\u5165"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsx)(o.li,{children:"2D \u969c\u788d\u7269\u8fb9\u754c\u6846\u3002"}),"\n"]}),"\n",(0,t.jsx)(o.h2,{id:"\u8f93\u51fa",children:"\u8f93\u51fa"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsx)(o.li,{children:"\u969c\u788d\u7269\u7684 3D \u4f4d\u7f6e\u4f5c\u4e3a\u70b9\u3002"}),"\n"]}),"\n",(0,t.jsx)(o.h2,{id:"\u793a\u4f8b\u7ed8\u5236-\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9",children:"\u793a\u4f8b\u7ed8\u5236 \uff08\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9\uff09"}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{src:"https://i.imgur.com/Aq33qy5.png",alt:"Imgur"})}),"\n",(0,t.jsx)(o.h2,{id:"\u56fe\u63cf\u8ff0",children:"\u56fe\u63cf\u8ff0"}),"\n",(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-yaml",children:"  - id: obstacle_location_op\n    operator: \n      outputs:\n        - obstacles\n      inputs:\n        lidar_pc: oasis_agent/lidar_pc\n        obstacles_bbox: yolov5/bbox\n        position: oasis_agent/position\n      python: ../../operators/obstacle_location_op.py\n"})}),"\n",(0,t.jsx)(o.h2,{id:"\u56fe\u53ef\u89c6\u5316",children:"\u56fe\u53ef\u89c6\u5316"}),"\n",(0,t.jsx)(o.mermaid,{value:"        flowchart TB\n  oasis_agent\nsubgraph yolov5\n  yolov5/op[op]\nend\nsubgraph fot_op\n  fot_op/op[op]\nend\nsubgraph obstacle_location_op\n  obstacle_location_op/op[op]\nend\n  oasis_agent -- lidar_pc --\x3e obstacle_location_op/op\n  yolov5/op -- bbox as obstacles_bbox --\x3e obstacle_location_op/op\n  oasis_agent -- position --\x3e obstacle_location_op/op\n  obstacle_location_op/op -- obstacles --\x3e fot_op/op"}),"\n",(0,t.jsx)(o.h2,{id:"\u65b9\u6cd5",children:"\u65b9\u6cd5"}),"\n",(0,t.jsx)(o.h3,{id:"__init__",children:(0,t.jsx)(o.code,{children:"__init__()"})}),"\n",(0,t.jsxs)(e,{children:[(0,t.jsx)("summary",{children:"\u6e90\u7801"}),(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-python",children:"    def __init__(self):\n        self.point_cloud = []\n        self.camera_point_cloud = []\n        self.ground_point_cloud = []\n        self.camera_ground_point_cloud = []\n        self.last_point_cloud = []\n        self.last_camera_point_cloud = []\n        self.obstacles = []\n        self.obstacles_bbox = []\n        self.position = []\n        self.lanes = []\n\n\n"})})]}),"\n",(0,t.jsx)(o.h3,{id:"on_event",children:(0,t.jsx)(o.code,{children:".on_event(...)"})}),"\n",(0,t.jsxs)(e,{children:[(0,t.jsx)("summary",{children:"\u6e90\u7801"}),(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-python",children:'\n    def on_event(\n        self,\n        dora_event: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n\n'})})]}),"\n",(0,t.jsx)(o.h3,{id:"on_input",children:(0,t.jsx)(o.code,{children:".on_input(...)"})}),"\n",(0,t.jsxs)(e,{children:[(0,t.jsx)("summary",{children:"\u6e90\u7801"}),(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-python",children:'\n    def on_input(\n        self,\n        dora_input: dict,\n        send_output: Callable[[str, bytes], None],\n    ):\n        if "lidar_pc" == dora_input["id"]:\n            point_cloud = np.array(dora_input["value"])\n            point_cloud = point_cloud.reshape((-1, 3))\n\n            # \u4ece Velodyne\u6fc0\u5149\u96f7\u8fbe\u8f74 \u81f3 \u76f8\u673a\u8f74\n            # \u4ece Velodyne\u6fc0\u5149\u96f7\u8fbe\u8f74:\n            # x -> \u5411\u524d, y -> \u5411\u53f3, z -> \u81f3\u9876\n            # \u81f3 \u76f8\u673a\u8f74:\n            # x -> \u5411\u53f3, y -> \u81f3\u5e95, z -> \u5411\u524d\n            point_cloud = np.dot(\n                point_cloud,\n                VELODYNE_MATRIX,\n            )\n\n            # \u4ec5 \u5411\u524d \u70b9 ( forward = z > 0.1 )\n            point_cloud = point_cloud[np.where(point_cloud[:, 2] > 0.1)]\n\n            # \u79fb\u9664\u5730\u9762\u70b9\u3002 Above lidar only ( bottom = y < 1.0 )\n            above_ground_point_index = np.where(point_cloud[:, 1] < 1.0)\n            point_cloud = point_cloud[above_ground_point_index]\n            self.ground_point_cloud = point_cloud[above_ground_point_index == False]\n\n            # 3D \u6570\u7ec4 -> 2D \u6570\u7ec4 \u4e0e index_x -> pixel x, index_y -> pixel_y, value -> z\n            camera_point_cloud = local_points_to_camera_view(\n                point_cloud, INTRINSIC_MATRIX\n            ).T\n            self.camera_ground_point_cloud = local_points_to_camera_view(\n                self.ground_point_cloud, INTRINSIC_MATRIX\n            ).T\n\n            self.camera_point_cloud = camera_point_cloud\n            self.point_cloud = point_cloud\n\n        elif "position" == dora_input["id"]:\n            # \u6dfb\u52a0\u4f20\u611f\u5668\u53d8\u6362\n            self.position = dora_input["value"].to_numpy()\n            self.extrinsic_matrix = get_extrinsic_matrix(\n                get_projection_matrix(self.position)\n            )\n\n        elif "lanes" == dora_input["id"]:\n            lanes = np.array(dora_input["value"]).reshape((-1, 60, 2))\n\n            knnr = KNeighborsRegressor(n_neighbors=4)\n            knnr.fit(self.camera_ground_point_cloud[:, :2], self.ground_point_cloud)\n\n            processed_lanes = []\n            for lane in lanes:\n                lane_location = knnr.predict(lane)\n                lane_location = np.array(lane_location)\n\n                lane_location = np.hstack(\n                    (\n                        lane_location,\n                        np.ones((lane_location.shape[0], 1)),\n                    )\n                )\n                lane_location = np.dot(lane_location, self.extrinsic_matrix.T)[:, :3]\n                processed_lanes.append(lane_location)\n            processed_lanes = pa.array(np.array(processed_lanes, np.float32).ravel())\n\n            send_output("global_lanes", processed_lanes, dora_input["metadata"])\n\n        elif "obstacles_bbox" == dora_input["id"]:\n            if len(self.position) == 0 or len(self.point_cloud) == 0:\n                return DoraStatus.CONTINUE\n\n            # bbox = np.array([[min_x, max_x, min_y, max_y, confidence, label], ... n_bbox ... ])\n            self.obstacles_bbox = np.array(dora_input["value"]).reshape((-1, 6))\n\n            obstacles_with_location = []\n            for obstacle_bb in self.obstacles_bbox:\n                [min_x, max_x, min_y, max_y, confidence, label] = obstacle_bb\n                z_points = self.point_cloud[\n                    np.where(\n                        (self.camera_point_cloud[:, 0] > min_x)\n                        & (self.camera_point_cloud[:, 0] < max_x)\n                        & (self.camera_point_cloud[:, 1] > min_y)\n                        & (self.camera_point_cloud[:, 1] < max_y)\n                    )\n                ]\n                if len(z_points) > 0:\n                    closest_point = z_points[\n                        z_points[:, 2].argsort()[int(len(z_points) / 4)]\n                    ]\n                    obstacles_with_location.append(closest_point)\n            if len(obstacles_with_location) > 0:\n                obstacles_with_location = np.array(obstacles_with_location)\n                obstacles_with_location = np.hstack(\n                    (\n                        obstacles_with_location,\n                        np.ones((obstacles_with_location.shape[0], 1)),\n                    )\n                )\n                obstacles_with_location = np.dot(\n                    obstacles_with_location, self.extrinsic_matrix.T\n                )[:, :3]\n\n                predictions = get_predictions(\n                    self.obstacles_bbox, obstacles_with_location\n                )\n                predictions_bytes = pa.array(np.array(predictions, np.float32).ravel())\n\n                send_output("obstacles", predictions_bytes, dora_input["metadata"])\n            else:\n                send_output(\n                    "obstacles",\n                    pa.array(np.array([]).ravel()),\n                    dora_input["metadata"],\n                )\n        return DoraStatus.CONTINUE\n\n\n'})})]})]})}function d(n={}){const{wrapper:o}={...(0,l.R)(),...n.components};return o?(0,t.jsx)(o,{...n,children:(0,t.jsx)(_,{...n})}):_(n)}},28453:(n,o,e)=>{e.d(o,{R:()=>a,x:()=>s});var t=e(96540);const l={},i=t.createContext(l);function a(n){const o=t.useContext(i);return t.useMemo((function(){return"function"==typeof n?n(o):{...o,...n}}),[o,n])}function s(n){let o;return o=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:a(n.components),t.createElement(i.Provider,{value:o},n.children)}}}]);