"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[6313],{62952:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var o=t(74848),a=t(28453);const r={},i="CUDA 0-Copy IPC",c={id:"guides/Development/Cuda",title:"CUDA 0-Copy IPC",description:"So let say you have a pytorch tensor on cuda and you want to share it between nodes.",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/guides/Development/Cuda.md",sourceDirName:"guides/Development",slug:"/guides/Development/Cuda",permalink:"/zh-CN/docs/guides/Development/Cuda",draft:!1,unlisted:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",frontMatter:{},sidebar:"guides",previous:{title:"Arrow",permalink:"/zh-CN/docs/guides/Development/Arrow"},next:{title:"\u52a8\u6001\u7ed3\u70b9",permalink:"/zh-CN/docs/guides/Development/dynamic-node"}},s={},d=[{value:"Installation",id:"installation",level:2},{value:"Sending data",id:"sending-data",level:2},{value:"Receiving data",id:"receiving-data",level:2}];function l(e){const n={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"cuda-0-copy-ipc",children:"CUDA 0-Copy IPC"}),"\n",(0,o.jsx)(n.p,{children:"So let say you have a pytorch tensor on cuda and you want to share it between nodes."}),"\n",(0,o.jsx)(n.p,{children:"Good news is that you can do it without copying the data using CUDA 0 Copy IPC."}),"\n",(0,o.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,o.jsx)(n.p,{children:"To use this feature, make sure to have the following requirements:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'\n# Install pyarrow with gpu support\nconda install pyarrow "arrow-cpp-proc=*=cuda" -c conda-forge\n\n## Test installation with\npython -c "import pyarrow.cuda"\n\n# Install numba for translation from arrow to torch\npip install numba\n\n## Test installation with\npython -c "import numba.cuda"\n\n# Install torch if it\'s not already present\npip install torch\n\n## Test installation with\npython -c "import torch; assert torch.cuda.is_available()"\n'})}),"\n",(0,o.jsx)(n.h2,{id:"sending-data",children:"Sending data"}),"\n",(0,o.jsx)(n.p,{children:"To create an IPC handle that is going to be sent between process, do the following:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import torch\nfrom dora.cuda import torch_to_ipc_buffer\n\ntorch_tensor = torch.tensor([1, 2, 3], dtype=torch.int64, device="cuda")\nipc_buffer, metadata = torch_to_ipc_buffer(torch_tensor)\nnode.send_output("latency", ipc_buffer, metadata)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"receiving-data",children:"Receiving data"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import pyarrow as pa\nfrom dora import Node\nfrom dora.cuda import ipc_buffer_to_ipc_handle, cudabuffer_to_torch\n\nctx = pa.cuda.context()\nnode = Node()\nevent = node.next() # Get an event with a torch handle\n\nipc_handle = ipc_buffer_to_ipc_handle(event["value"])\ncudabuffer = ctx.open_ipc_buffer(ipc_handle)\ntorch_tensor = cudabuffer_to_torch(cudabuffer, event["metadata"])  # on cuda\n'})})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var o=t(96540);const a={},r=o.createContext(a);function i(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);